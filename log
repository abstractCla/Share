6.倒排索引部分,值得借鉴.

书上1.5 tf-idf权重计算算法

8.分词器  三部分
	character filter:分词之前预处理,过滤掉HTML标签,特殊符号等
	tokenizer:分词
	token 标准化,大小写,同义词转换

14.动态映射,根据给定的数据,自动识别其类型

节点与分片,(分片又分为主分片和副本,主分片和副本不能在一个节点上),添加节点之后,Elasticsearch会自动分配分片,实现负载均衡,主分片和副本同样具有数据处理和路由的功能,借此实现负载均衡
每个分片都是一个最小工作单元，承载部分数据；每个分片都是一个lucene实例，有完整的建立索引和处理请求的能力
增加副本可以提高容错性

29.文档修改，删除原理解析  PUT对比POST方式

### 3.13 文档数据路由原理解析

1.文档路由到分片上：
 
 一个索引由多个分片构成，当添加(删除，修改)一个文档时，es就需要决定这个文档存储在哪个分片上，这个过程就称为数据路由(routing)
 
2.路由算法：

     shard=hash(routing) % number_of_pirmary_shards

示例：一个索引，3个primary shard

(1)每次增删改查时，都有一个routing值，默认是文档的_id的值

(2)对这个routing值使用哈希函数进行计算

(3)计算出的值再和主分片个数取余数

余数肯定在0---（number_of_pirmary_shards-1）之间，文档就在对应的shard上

routing值默认是文档的_id的值，也可以手动指定一个值，手动指定对于负载均衡以及提高批量读取的性能都有帮助

3.primary shard个数一旦确定就不能修改了



 3.20 分页查询中的deep paging问题 ,深度越深,性能越低

42.计算相关度分数
使用的是TF/IDF算法(Term Frequency&Inverse Document Frequency)

1.Term Frequency:我们查询的文本中的词条在document本中出现了多少次，出现次数越多，相关度越高

搜索内容： hello world

Hello，I love china.

Hello world,how are you!

2.Inverse Document  Frequency：我们查询的文本中的词条在索引的所有文档中出现了多少次，出现的次数越多，相关度越低

搜索内容：hello world

hello，what are you doing?

I like the world.

hello 在索引的所有文档中出现了500次，world出现了100次

3.Field-length(字段长度归约) norm:field越长，相关度越低

搜索内容：hello world

{"title":"hello,what's your name?","content":{"owieurowieuolsdjflk"}}

{"title":"hi,good morning","content":{"lkjkljkj.......world"}}

查看分数是如何计算的：

GET /lib3/user/_search?explain=true
{
    "query":{
        "match":{
            "interests": "duanlian,changge"
        }
    }
}

查看一个文档能否匹配上某个查询：

GET /lib3/user/2/_explain
{
    "query":{
        "match":{
            "interests": "duanlian,changge"
        }
    }
}



如果一次性要查出来比如10万条数据，需要把文档加载到内存中,那么性能会很差，此时一般会采取用scoll滚动查询，一批一批的查，直到所有数据都查询完为止。
1.scoll搜索会在第一次搜索的时候，保存一个当时的视图快照，之后只会基于该旧的视图快照提供数据搜索，如果这个期间数据变更，是不会让用户看到的

2.采用基于_doc(不使用_score)进行排序的方式，性能较高

3.每次发送scroll请求，我们还需要指定一个scoll参数，指定一个时间窗口，每次搜索请求只要在这个时间窗口内能完成就可以了

